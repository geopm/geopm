#!/usr/bin/env python3
#  Copyright (c) 2015 - 2021, Intel Corporation
#
#  Redistribution and use in source and binary forms, with or without
#  modification, are permitted provided that the following conditions
#  are met:
#
#      * Redistributions of source code must retain the above copyright
#        notice, this list of conditions and the following disclaimer.
#
#      * Redistributions in binary form must reproduce the above copyright
#        notice, this list of conditions and the following disclaimer in
#        the documentation and/or other materials provided with the
#        distribution.
#
#      * Neither the name of Intel Corporation nor the names of its
#        contributors may be used to endorse or promote products derived
#        from this software without specific prior written permission.
#
#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
#  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
#  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
#  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
#  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
#  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
#  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
#  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
#  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
#  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY LOG OF THE USE
#  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
#

import torch
from torch import nn
from random import uniform
import numpy as np
import sys

import pandas as pd
import argparse
import code

from ray import tune
from ray.tune import CLIReporter
from ray.tune.schedulers import ASHAScheduler

from functools import partial

BATCH_SIZE = 1000
EPOCH_SIZE = 5
DEPTH_FC_MIN = 2
DEPTH_FC_MAX = 11
TUNE_SAMPLES = 40

def main():
    parser = argparse.ArgumentParser(
        description='Run ML training based on CPU frequency sweep data.')
    parser.add_argument('input', help='HDF file containing the training data, '
                                      'generated by process_cpu_frequency_sweep.py.')
    parser.add_argument('output', help='Output directory for the tensorflow model.')
    parser.add_argument('--leave-app-out',
                        help='Leave the named app out of the training set')
    parser.add_argument('--train-hyperparams', action='store_true',
                        help='Train model hyper parameters')
    args = parser.parse_args()

    df_traces = pd.read_hdf(args.input)

    y_columns = ['phi-freq']
    X_columns = ['POWER_PACKAGE-package-0',
                 'CPU_FREQUENCY_STATUS-package-0',
                 'TEMPERATURE_CORE-package-0',
                 'MSR::UNCORE_PERF_STATUS:FREQ-package-0',
                 'QM_CTR_SCALED_RATE-package-0']

    ratios = [['INSTRUCTIONS_RETIRED-package-0', 'CYCLES_THREAD-package-0'],
              ['INSTRUCTIONS_RETIRED-package-0', 'ENERGY_PACKAGE-package-0'],
              ['MSR::APERF:ACNT-package-0', 'MSR::MPERF:MCNT-package-0'],
              ['MSR::PPERF:PCNT-package-0', 'MSR::MPERF:MCNT-package-0'],
              ['MSR::PPERF:PCNT-package-0', 'MSR::APERF:ACNT-package-0']]

    for num,den in ratios:
        name = 'delta_{}/delta_{}'.format(num, den)
        X_columns.append(name)
        df_traces[name] = df_traces[num].diff() / df_traces[den].diff()
    X_columns.append("phi")

    #Print phi to phi-freq mapping
    print(df_traces.pivot_table('phi-freq', 'phi', 'app-config'))

    # Exclude rows missing data in any of the columns of interest. Otherwise,
    # NaN values propagate into every weight in the model.
    # And replace Inf with NaN
    df_traces.replace([np.inf, -np.inf], np.nan, inplace=True)
    is_missing_data = df_traces[X_columns + y_columns].isna().sum(axis=1) > 0
    df_traces = df_traces.loc[~is_missing_data]

    # Assume all traces for testing to start.  This is a simplification for
    # the hyperparameter tuning work.
    # TODO: A full breakout of train, val, and test sets should be provided
    df_test = df_traces

    # Ignore applications that are requested to be ignored by the user. This
    # may be useful for a case where the training data includes many
    # application sweeps. Then, a single sweep output can be re-used for many
    # models, and each model can ignore one application. When evaluating the
    # model's performance on an applcation, we should use a model that excludes
    # that application from the training set so we can get a better idea about
    # how the model might generalize to unseen workloads.
    if args.leave_app_out is not None:
        app_config_list = [e for e in df_traces['app-config'].unique() if args.leave_app_out in e]
        if app_config_list is None:
            print('Error: {args.leave_app_out} not in the available training sets')
            exit(1)
        else:
            df_test_list = []
            for app_config in app_config_list:
                #If we exclude it from training we should save it for testing
                df_test_list.append(df_traces.loc[df_traces['app-config'] == app_config])

                #exclude from training
                df_traces = df_traces.loc[df_traces['app-config'] != app_config]

            #If using leave one out only use those cases for the test case
            df_test = pd.concat(df_test_list)

    df_train = df_traces
    df_x_train = df_train[X_columns]
    df_y_train = df_train[y_columns]
    df_y_train /= 1e9

    x_train = torch.tensor(df_x_train.to_numpy()).float()
    y_train = torch.tensor(df_y_train.to_numpy()).float()

    train_tensor = torch.utils.data.TensorDataset(x_train, y_train)
    train_loader = torch.utils.data.DataLoader(dataset = train_tensor, batch_size = BATCH_SIZE, shuffle = True)

    df_x_test = df_test[X_columns]
    df_y_test = df_test[y_columns]
    df_y_test /= 1e9

    x_test = torch.tensor(df_x_test.to_numpy()).float()
    y_test = torch.tensor(df_y_test.to_numpy()).float()

    test_tensor = torch.utils.data.TensorDataset(x_test, y_test)
    test_loader = torch.utils.data.DataLoader(dataset = test_tensor, batch_size = BATCH_SIZE, shuffle = True)

    if args.train_hyperparams:
        config = {
            "width_fc" : tune.sample_from(lambda _: 2**np.random.randint(2, 7)),
            "depth_fc" : tune.randint(2,11),
            "lr" : tune.loguniform(1e-4, 1e-1)
        }

        scheduler = ASHAScheduler(
            metric="accuracy",
            mode="max",
            #max_t=100, #maximum time for a trial
            grace_period=1,
            reduction_factor=2)

        reporter = CLIReporter(
            metric_columns=["accuracy"]) #TODO: we may want to switch to using loss from the validation set when we add it

        result = tune.run(
            tune.with_parameters(training_loop, input_size=len(X_columns), train_loader=train_loader, test_loader=test_loader),
            #resources_per_trial={"cpu":, "gpu":}, #TODO: specifying CPU availability
            config = config,
            num_samples=TUNE_SAMPLES,
            scheduler = scheduler,
            progress_reporter=reporter,
            )

        best_trial = result.get_best_trial("accuracy", "max", "last")
        print("Best config: {}".format(best_trial.config))
        print("\taccuracy: {}".format(best_trial.last_result["accuracy"]))
        best_model = P3Net(width_input=len(X_columns), width_fc=best_trial.config["width_fc"], depth_fc=best_trial.config["depth_fc"])
    else:
        best_model = P3Net(width_input=len(X_columns), width_fc=len(X_columns), depth_fc=2)
        learning_rate = 1e-3
        optimizer = torch.optim.Adam(best_model.parameters(), lr=learning_rate)

        print("batch_size:{}, epoch_count:{}, learning_rate={}".format(BATCH_SIZE, EPOCH_SIZE, learning_rate))
        for epoch in range(EPOCH_SIZE):
            print("\tepoch:{}".format(epoch))
            train(best_model, optimizer, train_loader)

        print("Begin Testing:")
        accuracy = test(best_model, test_loader);
        print('\tAccuracy: {:.2f}%.'.format(accuracy*100))

    print('Saving model (non-scripted and in training mode) as a precaution here: {}'.format(args.output + '-pre-torchscript'))
    torch.save(best_model.state_dict(), "{}".format(args.output + '-pre-torchscript'))

    best_model.eval()
    model_scripted = torch.jit.script(best_model)
    model_scripted.save(args.output)
    print("Model saved to {}".format(args.output))


def training_loop(config, input_size, train_loader, test_loader):
    model = P3Net(width_input=input_size, width_fc=config["width_fc"], depth_fc=config["depth_fc"])
    learning_rate = config["lr"]
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

    print("batch_size:{}, epoch_count:{}, learning_rate={}".format(BATCH_SIZE, EPOCH_SIZE, learning_rate))
    for epoch in range(EPOCH_SIZE):
        # TODO: We're using the test case here to help determine accuracy, as opposed to
        #       having a separate validation case that is evaluated as part of the training
        #       loop.  This is an implementation simplification and there may be benefit
        #       to introducing a proper validation set and using its accuracy instead
        train(model, optimizer, train_loader)
        accuracy = test(model, test_loader);

        # Send the current training result back to Tune
        tune.report(accuracy=accuracy)

    model.eval()

def train(model, optimizer, train_loader):
    loss_fn = nn.MSELoss()
    for idx, (inputs, target_control) in enumerate(train_loader):
        model.train()
        # Clear gradient
        optimizer.zero_grad()
        # Get model output
        predicted_control = model(inputs)
        # loss calculation vs target
        loss = loss_fn(predicted_control, target_control)
        loss.backward()

        # update model weights
        optimizer.step()

def test(model, test_loader):
    model.eval()
    prediction_total = 0
    prediction_correct = 0
    tolerance = 0.05
    prediction_within_tolerance = 0
    with torch.no_grad():
        for idx, (inputs, target_control) in enumerate(test_loader):
            prediction_total += inputs.size(0)

            # Run inputs through model, save prediction
            predicted_control = model(inputs)
            # Round to nearest 100 MHz increment
            predicted_control = np.round(predicted_control,1)

            prediction_correct += (target_control == predicted_control).sum().item()

    return prediction_correct/prediction_total

class P3Net(nn.Module):
    def __init__(self, width_input, width_fc, depth_fc):
        super(P3Net, self).__init__()
        self.depth_fc = depth_fc
        self.norm1 = nn.BatchNorm1d(width_input)
        self.fc1 = nn.Linear(width_input, width_fc)
        self.fc2 = nn.Linear(width_fc, width_fc)
        self.sigmoid = nn.Sigmoid()
        self.linear_output = nn.Linear(width_fc, 1)

    def forward(self, x):
        x = self.norm1(x)
        x = self.fc1(x)
        x = self.sigmoid(x)
        for d in range(self.depth_fc):
            x = self.fc2(x)
            x = self.sigmoid(x)
        x = self.linear_output(x)
        return x

if __name__ == "__main__":
    main()
