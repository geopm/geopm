#!/usr/bin/env python3
#
#  Copyright (c) 2015 - 2022, Intel Corporation
#  SPDX-License-Identifier: BSD-3-Clause
#

"""
This integration test verifies that the node_torch agent can improve
efficiency of an application.  It is intended to run after the
test_node_torch_agent and test_cpu_torch_agent integration tests
as it relies upon the models generated by those tests
"""
import sys
import unittest
import os
from pathlib import Path
import shutil
from experiment import machine
from types import SimpleNamespace

import geopmpy.agent
import geopmpy.io

from integration.test import util
from integration.test import geopm_test_launcher
from apps.parres import parres
from experiment.monitor import monitor
from pytorch_experiment import node_torch
import process_gpu_frequency_sweep
import process_cpu_frequency_sweep

import importlib
train_cpu_model = importlib.import_module("train_gpu_model-pytorch")
train_gpu_model = importlib.import_module("train_cpu_model-pytorch")

@util.skip_unless_do_launch()
@util.skip_unless_gpu()
@util.skip_unless_workload_exists("apps/parres/Kernels/Cxx11/dgemm-mpi-cublas")
@util.skip_unless_workload_exists("apps/parres/Kernels/Cxx11/nstream-mpi-cuda")
@util.skip_unless_workload_exists("apps/arithmetic_intensity/ARITHMETIC_INTENSITY/bench_sse")
@util.skip_unless_workload_exists("apps/arithmetic_intensity/ARITHMETIC_INTENSITY/bench_avx2")
@util.skip_unless_workload_exists("apps/arithmetic_intensity/ARITHMETIC_INTENSITY/bench_avx512")
class TestIntegration_node_torch(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        """
        Setup applications, execute, and set up class variables.
        """
        # TODO: check agent exists
        # TODO: check GEOPM_PLUGIN_PATH
        # TODO: Implement a cleaner check for if TORCH_ROOT is set
        os.environ["TORCH_ROOT"]

        ################
        # Monitor Runs #
        ################
        # STREAM
        output_dir = Path(__file__).resolve().parent.joinpath('test_node_torch_output/stream_monitor')
        if output_dir.exists() and output_dir.is_dir():
            shutil.rmtree(output_dir)
        mach = machine.init_output_dir(output_dir)
        cls._stream_monitor_dir = output_dir

        experiment_args = SimpleNamespace(
            output_dir=output_dir,
            node_count=1,
            parres_cores_per_node=None,
            parres_gpus_per_node=None,
            parres_cores_per_rank=1,
            parres_init_setup=None,
            parres_exp_setup=None,
            parres_teardown=None,
            parres_args=None,
            trial_count=1,
            cool_off_time=3,
            enable_traces=False,
            enable_profile_traces=False,
        )

        stream_app_conf = parres.create_nstream_appconf(mach, experiment_args)

        monitor.launch(app_conf=stream_app_conf, args=experiment_args,
                       experiment_cli_args=[])

        # DGEMM
        output_dir = Path(__file__).resolve().parent.joinpath('test_node_torch_output/dgemm_monitor')
        if output_dir.exists() and output_dir.is_dir():
            shutil.rmtree(output_dir)
        mach = machine.init_output_dir(output_dir)
        cls._dgemm_monitor_dir = output_dir

        experiment_args = SimpleNamespace(
            output_dir=output_dir,
            node_count=1,
            parres_cores_per_node=None,
            parres_gpus_per_node=None,
            parres_cores_per_rank=1,
            parres_init_setup=None,
            parres_exp_setup=None,
            parres_teardown=None,
            parres_args=None,
            trial_count=1,
            cool_off_time=3,
            enable_traces=False,
            enable_profile_traces=False,
        )

        dgemm_app_conf = parres.create_dgemm_appconf(mach, experiment_args)

        monitor.launch(app_conf=dgemm_app_conf, args=experiment_args,
                       experiment_cli_args=[])

        # Assuming previous integration tests have completed
        # the frequency sweeps and training are not required
        cls._dgemm_gpu_freq_sweep_dir = Path(__file__).resolve().parent.joinpath('test_gpu_pytorch_output/dgemm_gpu_freq_sweep')
        cls._aib_uncore_freq_sweep_dir = Path(__file__).resolve().parent.joinpath('test_cpu_pytorch_output/aib_frequency_sweep')
        pytorch_gpu_model = str(cls._dgemm_gpu_freq_sweep_dir.joinpath('gpu_control_integration.pt'))
        pytorch_cpu_model = str(cls._aib_uncore_freq_sweep_dir.joinpath('cpu_control_integration.pt'))

        # If the torch_root/lib is included before we do the pytorch training the python pytorch
        # libraries will throw an error).  As such we add this immediately before run.
        os.environ["LD_LIBRARY_PATH"] = os.environ["LD_LIBRARY_PATH"] + ":" + os.environ["TORCH_ROOT"] + "/lib"

        #DGEMM
        output_dir = Path(__file__).resolve().parent.joinpath('test_node_torch_output/dgemm_agent')
        if output_dir.exists() and output_dir.is_dir():
            shutil.rmtree(output_dir)
        mach = machine.init_output_dir(output_dir)

        cls._dgemm_agent_dir = output_dir

        experiment_args = SimpleNamespace(
            output_dir=output_dir,
            node_count=1,
            parres_cores_per_node=None,
            parres_gpus_per_node=None,
            parres_cores_per_rank=1,
            parres_init_setup=None,
            parres_exp_setup=None,
            parres_teardown=None,
            parres_args=None,
            trial_count=1,
            cool_off_time=3,
            enable_traces=False,
            enable_profile_traces=False,
            cpu_nn_path=pytorch_cpu_model,
            gpu_nn_path=pytorch_gpu_model,
        )

        app_conf = parres.create_dgemm_appconf(mach, experiment_args)

        node_torch.launch(app_conf=app_conf, args=experiment_args,
                            experiment_cli_args=[])

        #STREAM
        output_dir = Path(__file__).resolve().parent.joinpath('test_node_torch_output/stream_agent')
        if output_dir.exists() and output_dir.is_dir():
            shutil.rmtree(output_dir)
        mach = machine.init_output_dir(output_dir)

        cls._stream_agent_dir = output_dir

        experiment_args = SimpleNamespace(
            output_dir=output_dir,
            node_count=1,
            parres_cores_per_node=None,
            parres_gpus_per_node=None,
            parres_cores_per_rank=1,
            parres_init_setup=None,
            parres_exp_setup=None,
            parres_teardown=None,
            parres_args=None,
            trial_count=1,
            cool_off_time=3,
            enable_traces=False,
            enable_profile_traces=False,
            cpu_nn_path=pytorch_cpu_model,
            gpu_nn_path=pytorch_gpu_model,
        )

        app_conf = parres.create_nstream_appconf(mach, experiment_args)

        node_torch.launch(app_conf=app_conf, args=experiment_args,
                            experiment_cli_args=[])


    def tearDown(self):
        if sys.exc_info() != (None, None, None):
            TestIntegration_node_torch._keep_files = True

    @util.skip_unless_nvml()
    def test_node_torch_dgemm_nvidia(self):
        """
        PARRES DGEMM exhibits less energy consumption with the agent
        for all phi values.
        """
        pass

    @util.skip_unless_nvml()
    def test_node_torch_stream_nvidia(self):
        """
        PARRES NSTREAM exhibits less energy consumption with the agent
        for all phi values.
        """
        pass

if __name__ == '__main__':
    # Call do_launch to clear non-pyunit command line option
    util.do_launch()
    unittest.main()
